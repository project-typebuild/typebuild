{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from task_graph import TaskGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_graph = TaskGraph(\"Create haikus on all seasons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "task_graph.add_task(\n",
    "    task_name='Fall haiku', \n",
    "    agent_name='haiku_agent',\n",
    "    task_description='Write a haiku about the Fall season',\n",
    "    )\n",
    "\n",
    "task_graph.add_task(\n",
    "    task_name='Winter haiku', \n",
    "    agent_name='haiku_agent',\n",
    "    task_description='Write a haiku about winter',\n",
    "    )\n",
    "task_graph.add_task(\n",
    "    task_name='Get Data', \n",
    "    agent_name='haiku_agent',\n",
    "    task_description='Write a haiku about the Fall season',\n",
    "    )\n",
    "\n",
    "task_graph.add_task(\n",
    "    task_name='Upload data', \n",
    "    agent_name='haiku_agent',\n",
    "    task_description='Write a haiku about winter',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_graph.add_dependency('Winter haiku', 'Fall haiku')\n",
    "task_graph.add_dependency('Get Data', 'Upload data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Winter haiku**: \n",
      "  - **Fall haiku**: \n",
      "- **Get Data**: \n",
      "  - **Upload data**: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task_graph.generate_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_info = task_graph.graph.nodes['Fall haiku']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a haiku about the Fall season'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_info['task'].task_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_task_desc = f\"\"\"\n",
    "You are helping the user complete the task: {task_graph.name}.  It has {task_graph.graph.number_of_nodes()}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Task(\n",
    "    task_name='orchestration',\n",
    "    agent_name='agent_manager',\n",
    "    task_description=orchestration_task_desc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get_system_instruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_graph.add_task('Task1.1', sequence=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_graph.add_dependency('Task1', 'Task1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_graph.update_task('Task1.1', completed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = task_graph.get_next_task('Task1.1')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'travis+coan'\n",
    "max_results = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = f\"http://export.arxiv.org/api/query?search_query={query}&start=0&max_results={max_results}\"\n",
    "# Get the response\n",
    "response = requests.get(api_url)\n",
    "# Get the content\n",
    "content = response.content\n",
    "# Parse the content\n",
    "soup = BeautifulSoup(content, 'xml')\n",
    "\n",
    "# Get the entries\n",
    "entries = soup.find_all('entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for entry in entries:\n",
    "    title = entry.title.text\n",
    "    authors = [author.find('name').text for author in entry.find_all('author')]\n",
    "    summary = entry.summary.text\n",
    "    link = entry.link['href']\n",
    "    date_of_publication = entry.published.text\n",
    "\n",
    "    result = {\n",
    "        'title': title,\n",
    "        'author': authors,\n",
    "        'summary': summary,\n",
    "        'link': link,\n",
    "        'date_of_publication': date_of_publication\n",
    "    }\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Using Semantic Similarity and Text Embedding to Measure the Social Media\\n  Echo of Strategic Communications',\n",
       "  'author': ['Tristan J. B. Cann',\n",
       "   'Ben Dennes',\n",
       "   'Travis Coan',\n",
       "   \"Saffron O'Neill\",\n",
       "   'Hywel T. P. Williams'],\n",
       "  'summary': '  Online discourse covers a wide range of topics and many actors tailor their\\ncontent to impact online discussions through carefully crafted messages and\\ntargeted campaigns. Yet the scale and diversity of online media content make it\\ndifficult to evaluate the impact of a particular message. In this paper, we\\npresent a new technique that leverages semantic similarity to quantify the\\nchange in the discussion after a particular message has been published. We use\\na set of press releases from environmental organisations and tweets from the\\nclimate change debate to show that our novel approach reveals a heavy-tailed\\ndistribution of response in online discourse to strategic communications.\\n',\n",
       "  'link': 'http://arxiv.org/abs/2303.16694v1',\n",
       "  'date_of_publication': '2023-03-29T13:46:07Z'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
